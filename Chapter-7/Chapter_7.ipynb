{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/LOCAL2/gjin/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 11s, trn_loss: 1.8947, trn_acc: 37.22%, adv_loss: 1.8992, adv_acc: 37.17%\n",
      "Epoch 2: 11s, trn_loss: 1.0717, trn_acc: 60.74%, adv_loss: 1.0803, adv_acc: 60.30%\n",
      "Epoch 3: 11s, trn_loss: 0.8675, trn_acc: 65.08%, adv_loss: 0.8785, adv_acc: 65.17%\n",
      "Epoch 4: 11s, trn_loss: 0.7730, trn_acc: 71.28%, adv_loss: 0.7858, adv_acc: 70.74%\n",
      "Epoch 5: 10s, trn_loss: 0.6936, trn_acc: 74.45%, adv_loss: 0.7090, adv_acc: 73.87%\n",
      "Epoch 6: 10s, trn_loss: 0.6499, trn_acc: 76.08%, adv_loss: 0.6695, adv_acc: 75.24%\n",
      "Epoch 7: 10s, trn_loss: 0.6133, trn_acc: 78.57%, adv_loss: 0.6342, adv_acc: 77.63%\n",
      "Epoch 8: 10s, trn_loss: 0.5689, trn_acc: 79.84%, adv_loss: 0.5938, adv_acc: 78.65%\n",
      "Epoch 9: 10s, trn_loss: 0.5670, trn_acc: 79.51%, adv_loss: 0.5957, adv_acc: 78.31%\n",
      "Epoch 10: 11s, trn_loss: 0.5311, trn_acc: 81.41%, adv_loss: 0.5626, adv_acc: 79.99%\n",
      "epsilon p:  tensor(0.3006)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "# input id\n",
    "id_ = 1000\n",
    "\n",
    "# setup training parameters\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Training')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for testing (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[]) \n",
    "\n",
    "# judge cuda is available or not\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "#device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "############################################################################\n",
    "################################don't modify################################\n",
    "############################################################################\n",
    "class Dataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.data_ = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.data_:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:]/255)\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(root='../data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "# define fully connected network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "############################################################################\n",
    "############################################################################\n",
    "############################################################################\n",
    "\n",
    "'generate adversarial data, you can define your adversarial method'\n",
    "def adv_attack(model, X, y, device):\n",
    "    X_adv = Variable(X.data)\n",
    "    random_noise = torch.FloatTensor(*X_adv.shape).uniform_(-0.3, 0.3).to(device)\n",
    "    X_adv = Variable(X_adv.data + random_noise)\n",
    "    return X_adv\n",
    "\n",
    "'train function, you can use adversarial training'\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(data.size(0),28*28)\n",
    "        \n",
    "        #use adverserial data to train the defense model\n",
    "        #adv_data = adv_attack(model, data, target, device=device)\n",
    "        \n",
    "        #clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #compute loss\n",
    "        #loss = F.cross_entropy(model(adv_data), target)\n",
    "        loss = F.cross_entropy(model(data), target)\n",
    "        \n",
    "        #get gradients and update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "'predict function'\n",
    "def eval_test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.view(data.size(0),28*28)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "def eval_adv_test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            adv_data = adv_attack(model, data, target, device=device)\n",
    "            adv_data = adv_data.view(adv_data.size(0),28*28)\n",
    "            output = model(adv_data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "'main function, train the dataset and print train loss, test loss for each epoch'\n",
    "def train_model():\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        #training\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        \n",
    "        #get trnloss and testloss\n",
    "        trnloss, trnacc = eval_test(model, device, train_loader)\n",
    "        advloss, advacc = eval_adv_test(model, device, train_loader)\n",
    "        \n",
    "        #print trnloss and testloss\n",
    "        print('Epoch '+str(epoch)+': '+str(int(time.time()-start_time))+'s', end=', ')\n",
    "        print('trn_loss: {:.4f}, trn_acc: {:.2f}%'.format(trnloss, 100. * trnacc), end=', ')\n",
    "        print('adv_loss: {:.4f}, adv_acc: {:.2f}%'.format(advloss, 100. * advacc))\n",
    "    \n",
    "    #save the model\n",
    "    torch.save(model.state_dict(), str(id_)+'.pt')\n",
    "    return model\n",
    "\n",
    "'compute perturbation distance'\n",
    "def p_distance(model, train_loader, device):\n",
    "    p = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        adv_data = adv_attack(model, data, target, device=device)\n",
    "        p += torch.norm(data-adv_data, float('inf'))\n",
    "    print('epsilon p: ',p/batch_idx)\n",
    "\n",
    "'annotate the following code in the submission file'\n",
    "#model = train_model()\n",
    "#p_distance(model, train_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
